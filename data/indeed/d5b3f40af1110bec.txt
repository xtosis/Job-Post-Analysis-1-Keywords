['<div id="jobDescriptionText" class="jobsearch-jobDescriptionText"><p><b>CTC006022 : Analyste, ingénierie des données</b></p><p><b>Location : </b> Montreal, Quebec<br><b>Field : </b> Data Engineer<br><b>Position Type : </b> Contract<br><b>Starting : </b> June 18, 2021<br><b>Ending : </b> December 18, 2021<br><b>Resources Required : </b> 1</p><p>Position Description</p><ul><li>We are looking for 2 resources.</li><li>Remote work 100%</li><li>The mandate is renewable.</li><li>Languages required: French, bilingual an asset</li></ul><p>Description of the mandate</p><ul><li>Work with Data Owners and Data Stewards to implement the data quality controls and rules they have defined in the different environments</li></ul><ul><li>Connect to the various banking systems via existing APIs, or by creating new APIs, to obtain the data to be controlled or validated</li></ul><ul><li>Documentation of transformation and validation applied to data Knowledge</li></ul><ul><li>Banking and Payments domain</li></ul><ul><li>Experience in financial transaction analysis</li><li>Knowledge of RPCFAT regulations</li><li>Experience with systems containing financial data (cards, transactions, payment data, etc.)</li></ul><ul><li>Developer</li></ul><ul><li>DevOps tools (GIT, Maven/Gradle, Jenkins, Nexus, Atlassian Jira &amp; Confluence, Bitbucket, GitHub)</li><li>Linux and infrastructure tools (Docker, Kubernetes, Terraform)</li><li>Micro-services and APIs (REST, Kafka, MQ or other broker), SOA, JSON</li><li>AWS and Openshift (Docker and Kubernetes)</li><li>Best practices in software engineering (BDD, TDD, SOLID, Clean Code, DevOps)</li><li>Hands-on experience with Kafka connectors, such as MQ connectors, Elastic Search connectors, JDBC connectors, file stream connector, JMS source connectors, Tasks, Workers, converters, Transforms</li></ul><ul><li>Data engineering</li></ul><ul><li>Datahub framework experience: Raw -? Curated -? Consumption - Strong experience in developing massive data ingestion and flow scripts.</li><li>Experience in production and maintenance of software projects, especially in the megadata ecosystem</li><li>Experience in Distributed cluster-computing (Spark, Databricks, Beam...)</li><li>Experience with Melissa Data, or any other address formatting tool</li></ul><p>Nice to Have</p><ul><li>Knowledge of AML (Anti-Money Laundering) and KYC (Know Your Customer) principles</li></ul><p>Job Types: Temporary, Contract</p></div>']
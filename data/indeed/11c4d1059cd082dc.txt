['<div id="jobDescriptionText" class="jobsearch-jobDescriptionText"><p></p><div><p>At CN, we work together to move our company—and North America—forward. Be part of our Information &amp; Technology (I&amp;T) team, a critical piece of the engine that keeps us in motion. From enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value-added tasks. You will be able to develop your skills and career in our close-knit, safety-focused culture working together as ONE TEAM. The careers we offer are meaningful because the work we do matters. Join us!</p>\n<p><b>\nJob Summary</b></p>\n<p>\nThe Expert Data Engineering is responsible for building, managing, and optimizing data pipelines, moving them effectively into production for key data and analytics consumers, shaping the enterprise Data as a Service (DaaS) model and delivering on IT business models. The Expert Data Engineering develops best practices and optimizes data pipelines to deliver products and services aligned with business expectations. The incumbent plays a pivotal role in operationalizing data and analytics initiatives, defining and building CN’s data integration and DaaS platform roadmap.</p>\n<p><b>\nMain Responsibilities</b></p>\n<p><b>\nData Engineering</b></p>\n<ul>\n<li>Ensure optimal data delivery architecture and processes are consistent throughout ongoing projects</li>\n<li>Optimize CN’s data architecture to support the next generation of products and data initiatives</li>\n<li>Build, manage, and optimize data pipelines, moving them effectively into production for key data and analytics consumers such as business or data analysts and data scientists</li>\n<li>Build data and domain event models, implement business rules, and engineer scalable data pipelines</li>\n<li>Ensure compliance with data governance and security requirements while creating, improving and operationalizing integrated and reusable data pipelines</li>\n<li>Enable faster data access, integrate data reuse, and improve time-to-solution for data and analytics initiatives</li>\n<li>Integrate analytics and data science results with business processes</li>\n<li>Promote effective data management practices</li>\n</ul>\n<p><b>Data Design</b></p>\n<ul>\n<li>Collaborate with stakeholders and architects to model data landscape and define secure data exchange approaches</li>\n<li>Meet with stakeholders to identify fit-for-purpose within CN’s existing data ecosystem and deliver options and agile solutions</li>\n<li>Design and develop processing pipelines that ingest data into Data Hubs</li>\n<li>Expose the data into meaningful formats, like GraphQL</li>\n<li>Provide day-to-day support and technical expertise to both technical and non-technical teams</li>\n<li>Participate in building data engineering expertise and framework</li>\n<li>Translate business needs into technical requirements</li>\n</ul>\n<p><b>Data Development</b></p>\n<ul>\n<li>Acquire, ingest and process data from multiple sources and systems</li>\n<li>Design and develop Extract, Transform, and Load (ETL) pipelines using multiple sources of data in various formats</li>\n<li>Conduct metadata management, data cleansing and preparation</li>\n<li>Produce well documented quality codes</li>\n</ul>\n<p><b>Data Operations</b></p>\n<ul>\n<li>Use Agile methodologies to streamline project delivery aligned with goals, timelines, and budget</li>\n<li>Build monitoring and debugging tools to analyze data pipelines</li>\n<li>Help unify software development and operations seamlessly, efficiently, and cost effectively</li>\n<li>Improve software quality, automate processes, and accelerate software releases</li>\n</ul>\n<p><b>Data Quality Assurance</b></p>\n<ul>\n<li>Use Agile development practises for code reviews and testing to develop and deliver data pipelines</li>\n<li>Develop and implement test plans and scripts for various data quality processes</li>\n<li>Maintain manual and automated test scripts</li>\n</ul>\n<p><b>Working Conditions</b></p>\n<p>\nThe role has standard working conditions in an office environment with a regular workweek from Monday to Friday and offers remote work.</p>\n<p><b>\nRequirements</b></p>\n<p><b>\nExperience</b></p>\n<p>\nData Engineering</p>\n<ul>\n<li>Minimum 5 years of experience in a data engineering role, working in different data management disciplines including data integration, modelling, optimization and quality</li>\n<li>Experience working in cross-functional teams and collaborating with business stakeholders in support of a departmental or multi-departmental data management and analytics initiative</li>\n<li>Experience with at least 2 of the following technologies: Python, Scala, SQL, Java</li>\n<li>Experience with Big Data technologies such as Hadoop, Hive, HBase, Spark, etc.</li>\n<li>Experience with Cloud and non-Cloud based Hadoop ecosystem</li>\n<li>Experience with Cloud platforms such as Azure, Google Platform or Databricks</li>\n<li>Experience with traditional data warehousing and ETL tools (Informatica, Talend, Pentaho, DataStage)</li>\n<li>Experience with Linux and shell scripting</li>\n<li>Experience deploying applications into production environments such as code packaging, integration testing, monitoring and release management</li>\n<li>Experience with multiple database technologies such as Distributed Processing (Spark, Hadoop, EMR), traditional RDBMS (MS SQL Server, Oracle, DB2, MySQL, PostgreSQL), NoSQL (MongoDB, DynamoDB, Cassandra)</li>\n<li>Experience working in an Agile team environment</li>\n</ul>\n<p><b>Education/Certification/Designation</b></p>\n<ul>\n<li>Bachelor\'s Degree in Computer Science, Electrical Engineering or Software Engineering</li>\n<li>Master’s Degree or PhD in Data Management, Data Analytics, Information Systems, or a related quantitative field*</li>\n<li>Professional Engineer (P.Eng.) Degree*</li>\n<li>Google or Azure Data Engineering certification*</li>\n</ul>\n<ul><li>Any designation for these above would be considered as an asset</li></ul>\n<p><b>\nCompetencies</b></p>\n<ul>\n<li>Inspires others with impactful communications and adapts to the audience through speech and writing</li>\n<li>Ability to communicate complex solutions</li>\n<li>Applies analytical thinking</li>\n<li>Innovates through problem solving</li>\n<li>Knows the business and stays current with industry trends to elevate expertise and work</li>\n<li>Demonstrates organizational abilities and detail oriented</li>\n<li>Collaborates with key internal stakeholders to enable higher productivity</li>\n<li>Works independently with little supervision</li>\n<li>Applies agile mindset</li>\n<li>Ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets</li>\n<li>Demonstrates commitment to high standards of ethics, regulatory compliance, customer service, and business integrity</li>\n</ul>\n<p><b>Technical Skills/Knowledge</b></p>\n<ul>\n<li>Strong data analytics and development skills</li>\n<li>Demonstrated creativity skills</li>\n<li>Expertise in a combination of Scala, Java or Python</li>\n<li>Expertise with Big Data architecture and distributed computing processes and platforms such as Map/Reduce, Hadoop, Hive, Spark, Kafka, etc.</li>\n<li>Expertise with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto)</li>\n<li>Knowledge of software engineering best practices such as code reviews, testing frameworks, maintainability and readability</li>\n<li>Expertise with GraphQL*</li>\n</ul>\n<ul><li>Any knowledge for any of the above would be considered as an asset</li></ul>\n<p><b>\nOrganizational Impact</b></p>\n<p><b>\nDecision Making &amp; Impacts</b></p>\n<p>\nThe Expert Data Engineering is accountable for working with business stakeholders, Data and IT subject matter experts, and business leads to plan and delivery on the strategy and implementation roadmap of data pipelines.</p>\n<p><b>\nLevel of Interaction/Influence</b></p>\n<p>\nThe Expert Data Engineering interacts primarily (80%) with internal stakeholders and partially (20%) with external contacts.</p>\n<p><b>\nEmployees Supervised/Organizational Structure</b></p>\n<p>\nThe role requires indirect supervision of 8 to 12 consultants.</p>\n<p><b>\nAbout CN\n</b></p><p>As a leading North American transportation and logistics company, CN is a true backbone of the economy. With a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. We transport US$200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000-mile network spanning Canada and mid-America. CN is the only Canadian company listed in the Transportation and Transportation Infrastructure sector of the Dow Jones Sustainability World Index (DJSI). Launched in 1999, the DJSI World represents the gold standard for corporate sustainability. At CN, we work as ONE TEAM, focused on safety, sustainability and our customers, providing operational and supply chain excellence to deliver results.</p><p></p><p><i><br>\nCN is an employment equity employer and we encourage all qualified candidates to apply. We thank all applicants for their interest, however, only candidates under consideration will be contacted. Please monitor your email on a regular basis, as communication is primarily made through email.</i></p></div></div>']
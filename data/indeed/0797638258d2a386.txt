['<div id="jobDescriptionText" class="jobsearch-jobDescriptionText"><p><b>About Blackline</b></p><p>Blackline Safety is a world leader in the development and manufacturing of wirelessly connected safety products. We offer the broadest and most complete portfolio available in the industry. Our products are designed to save lives and we monitor personnel working alone in populated areas, complex indoor facilities, and the remote reaches of our planet. Blackline’s products are used to keep people safe in the event of falls, missed check-ins, person-downs, and exposure to explosive or toxic gas. Our design, development, sales, marketing, support, and production are all performed in-house at our headquarters in Calgary, AB. Blackline Safety is a publicly-traded company (TSXV: BLN).</p><p>Blackline Safety is looking for a Data Engineer to help build and drive our Blackline Analytics and Blackline Vision platform. We have a world-class connected safety system and we are building a Data analytics and Data science platform to match it.</p><p><b>Who are you?</b></p><p>You believe big data helps businesses solve real-world problems. You have an aptitude for engineering and manipulating various forms of data frameworks including but not limited to Data warehousing, Modeling, Analytics, and Integrations from various data sources. You are not bound to a single tool or platform and can solve problems in creative ways. You are proficient in different computing languages such as SQL, Python, DAX and aspire to learn alternate ways of resolving issues. You trust in data-driven problem solving and believe visualizing large datasets is a necessity to achieve that. You like to explore datasets to find insights that nobody else sees. You can communicate these ideas through visualizations. You are team-oriented, self-motivated, creative, and excited to find answers to questions that the answer might not be obvious without going through large amounts of data.</p><p><b>What will you do?</b></p><p>You have an ability and desire to work in our collaborative environment: open team room, pair programming and fluid interactions with all products and operations teams. You will be a part of a high performing team that is focused on building solutions utilizing various approaches including agile; capable of digesting real-time feedback and working smartly to advance Blackline Analytics and Blackline Vision platforms. You are self-driven, need minimal supervision and are comfortable pushing your own projects and getting things done.</p><p>You will be responsible for expanding and optimizing our data pipeline architecture, as well as optimizing data flows and collection for analytics and data science teams. The pipeline needs to be scalable, precise, repeatable, secure, and accurate. You will work with some of the largest and most varied data sets (both batch and real-time) in the wireless industry. You will expand and develop the Blackline analytics platform alongside other data analysts and data scientists to make data-driven decisions, build innovative data products and roll out advanced analytics. Your contribution will help us increase internal efficiencies and evolve our products and services by leveraging large and diverse datasets generated by customers from around the world. The data architecture and framework and the technologies include IoT, ECS, Fargate, RDS MySQL, RedShift, Spark, EMR, Kinesis (Streams, Firehose, Analytics), Lambda, Datalakes, Deltalakes, Event bus, DataDog, CD/CI pipelines on CodePipeline and CodeBuild, CloudFormation, ALP, Python, Java, and more.</p><p><b>Requirements: </b></p><ul><li>3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field.</li><li>Experience working with APIs, integrations into reporting documents, building API endpoints for real-time reporting</li><li>Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), Postgres, JSON as well as working familiarity with a variety of databases.</li><li>Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.</li><li>Experience with big data tools: Hadoop, Spark, Kafka, DataDog, EventBus, AWS cloud services: EC2, EMR, RDS, Redshift, API calls, API generation</li><li>Hands-on experience with Cloud Data Warehouse (Snowflake, Azure or Redshift) and Big Data technologies (e.g S3, Hadoop, Hive, Spark, Flink, Kafka, etc). Build processes supporting data transformation, data structures, metadata, dependency, and workload management.</li><li>A successful history of manipulating, processing, and extracting value from large, disconnected datasets using ETL/ELT, Matillion, SSIS, Trefecta, etc and integrating data from silos to a Master Data source</li><li>Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores</li></ul><p><b>Optional: </b></p><ul><li>Knowledge of NetSuite, other 3rd party software integrations</li><li>Knowledge of Satori Reporting or any other turnkey integrative reporting</li><li>Knowledge of Power platform operations, query, flow and BI and integrations</li><li>Knowledge of Master Data Management</li></ul><p><b>Blackline Safety offers: </b></p><ul><li>An exciting high-growth environment</li><li>An experienced, dynamic, and motivated team</li><li>Supportive, challenging, and collaborative work</li><li>Competitive salary and vacation</li><li>Medical, dental, and drug benefits</li><li>Company stock purchase plan with matching contributions</li></ul><p>Our clients depend on Blackline Safety to monitor the wellbeing of their employees at work — you can help to make a difference. Come work with Blackline Safety in an exciting, fast-paced work environment.</p><p>Job Types: Full-time, Permanent</p><p>Schedule:</p><ul><li>Monday to Friday</li></ul><p>Education:</p><ul><li>Bachelor\'s Degree (preferred)</li></ul><p>Experience:</p><ul><li>building API endpoints for real-time reporting: 3 years (preferred)</li><li>building and optimizing ‘big data’ data pipelines: 3 years (preferred)</li><li>big data tools: 3 years (preferred)</li><li>Data Engineering: 3 years (preferred)</li><li>Advanced SQL knowledge and relational database: 3 years (preferred)</li></ul><p>Work remotely:</p><ul><li>Temporarily due to COVID-19</li></ul></div>']